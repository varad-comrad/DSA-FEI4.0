{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Projeto Desenvolvido na Data Science Academy - www.datascienceacademy.com.br -->\n",
    "# <font color='blue'>Data Science Academy</font>\n",
    "## <font color='blue'>IA Generativa e LLMs Para Processamento de Linguagem Natural</font>\n",
    "## <font color='blue'>Projeto 1</font>\n",
    "## <font color='blue'>Converse com Seus PDFs - Criando Assistente Pessoal de IA com LLM e VectorDB</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalando e Carregando Pacotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://openai.com/product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.pinecone.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U pinecone-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.langchain.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para instalar todos os pacotes de uma vez, execute no terminal ou prompt de comando:\n",
    "\n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import openai\n",
    "import langchain\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Data Science Academy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraindo Texto de Arquivos PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para ler os arquivos em pdf\n",
    "def dsa_read_pdf(directory_path):\n",
    "    \n",
    "    # Acessa a pasta com o arquivo pdf\n",
    "    file_loader = PyPDFDirectoryLoader(directory_path)\n",
    "    \n",
    "    # Lê o documento da pasta\n",
    "    documents = file_loader.load()\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executa a função\n",
    "dsa_doc = dsa_read_pdf('arquivos/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A Habilidade Mais Importante na Era da Inteligência Artificial  \\n \\nA pandemia do COVID -19 acelerou o ritmo do desenvolvimento digital em todo o mundo, já que \\ntudo, desde reuniões até consultas médicas, ficou online. Isso pode soar como algo super \\npositivo.   \\nPara dezenas de milhões de trabalhadores, não.  \\nEles talvez não tenham as habilidades necessárias para competir nesse novo mundo. Eles são os \\ncontadores, os digitadores, os secretários executivos, procurando trabalho em uma nova \\neconomia na qual as pessoas contratadas têm títulos como “Engenheiro de Nuv em” ou “Hacker \\nde Crescimento” em seus currículos. Sem um esforço concentrado para retreiná -los, descobriram \\nos pesquisadores da RAND Europe, eles provavelmente serão deixados para trás.  \\nE não apenas eles. O custo dessa crescente lacuna de habilidades será medido em trilhões de \\ndólares e recairá mais fortemente em lugares que não possuem infraestrutura digital confiável, \\ncomo acesso à Internet ou fluência generalizada em habilidades digita is. À medida que a \\neconomia mundial luta para se levantar após o golpe do COVID -19, essa lacuna de habilidades \\nameaça continuar pressionando para baixo.  \\n“Simplesmente não há pessoas suficientes com as habilidades digitais certas para permitir a \\ntransformação que as empresas estão buscando”, disse Salil Gunashekar, líder de pesquisa e \\ndiretor associado da RAND Europe, que se concentra na política de ciência  e tecnologia.  \\nEm algum momento nos próximos anos, o mundo passará por um marco importante. O número \\nde horas trabalhadas pelas máquinas será igual ao número de horas trabalhadas pelos humanos. \\nUma pesquisa recente da Salesforce descobriu que três quartos dos trabalhador es do mundo se \\nsentem despreparados para os empregos que podem encontrar do outro lado desse marco.  \\nAqueles que planejam trabalhar em assistência médica ou serviços financeiros, por exemplo, \\npodem precisar saber como usar computadores com  Inteligência Artificial . Aqueles que desejam \\ntrabalhar em mineração de metais podem precisar saber como operar robôs e analisar Big Data. \\nUm contador pode ser tornar o operador de um robô de automação de processos.  \\nOs líderes empresariais alertam há anos que o que veem nos currículos não corresponde ao que \\nprecisam em novos funcionários. O Índice de Economia e Sociedade Digital da Europa descobriu \\nrecentemente que quase 60% dos empregadores estão tendo problemas para  preencher vagas \\ndigitais com candidatos qualificados. E, no entanto, as realidades pandêmicas não os deixaram \\nescolha: quatro em cada cinco líderes empresariais globais dizem que estão acelerando a \\nautomação de processos e tarefas do dia a dia dentro da e mpresa.  ', metadata={'source': 'arquivos/ArtigoDSA1.pdf', 'page': 0}),\n",
       " Document(page_content='As principais economias do mundo agora podem perder US$ 11,5 trilhões em crescimento \\npotencial até 2028 se não conseguirem preencher a lacuna de habilidades, estimou a empresa \\nglobal de consultoria e serviços profissionais Accenture. Índia, África do Sul e  México serão \\nespecialmente atingidos. O mesmo acontecerá com os grupos que menos podem arcar com a \\nperda econômica: idosos, minorias raciais e étnicas e pessoas que vivem em áreas rurais.  \\nO Fórum Econômico Mundial estima que 85 milhões de empregos podem ser perdidos para a \\nautomação nos próximos três anos em mais de uma dúzia de setores. Ao mesmo tempo, espera \\nque surjam 97 milhões de novos empregos melhor adaptados ao futuro do trabalho. N o papel, \\nisso deve ser uma vitória. Sem um grande compromisso para reter e retreinar os trabalhadores \\nexistentes, descobriu a RAND Europe, será uma perda para os funcionários e uma perda para os \\nempregadores.  \\nNão há soluções simples aqui. As empresas precisam se tornar mais ágeis na distribuição e \\nredistribuição de seus funcionários existentes para melhor atender às suas necessidades, em vez \\nde tentar recrutar para sair da lacuna de habilidades. Elas também pre cisam fazer mais para \\najudar esses funcionários a aprender as habilidades técnicas, como programação e análise de \\ndados, e as habilidades interpessoais, como trabalhar em equipe, de que precisam para ter \\nsucesso. Os governos nacionais podem ajudar investin do em programas vocacionais e outros \\napoios para trabalhadores desalocados.  \\nUm passo importante seria desenvolver uma “linguagem de habilidades” comum, escreveram os \\npesquisadores. Isso garantiria que candidatos e empregadores tivessem a mesma intenção ao \\nusar um termo como “Engenheiro de Nuvem” ou “Engenheiro de IA”. Isso ajudari a os gerentes \\nde contratação a avaliar rapidamente os candidatos com base nas habilidades que eles trazem \\npara o trabalho e não apenas no nome da faculdade em seu currículo (que no mundo atual já não \\ntem mais qualquer relevância).  \\nOs trabalhadores, entretanto, precisam mudar sua mentalidade. A educação não termina mais \\ncom um diploma do ensino médio ou um diploma universitário. As habilidades que eles têm \\nagora podem não ser relevantes em alguns anos. Como aconselhou um gerente de t ecnologia no \\nCanadá entrevistado durante a pesquisa: “Seja Bom em Aprender”.  \\nSim. Esta é a habilidade mais importante na era da Inteligência Artificial:   \\n“Seja Bom em Aprender”.  \\n \\nA transformação digital requer que você aprenda, desaprenda, reaprenda e permaneça nesse \\nciclo se deseja realmente manter sua empregabilidade. A capacidade de adaptação a novas \\ntecnologias e a habilidade em aprender cada vez mais rápido, é o que vai diferenciar você das \\nmáquinas.  ', metadata={'source': 'arquivos/ArtigoDSA1.pdf', 'page': 1}),\n",
       " Document(page_content='Não importa sua área, seu mercado, sua graduação, sua idade ou seu gênero. O mundo está \\npassando por uma profunda transformação digital e os empregos como conhecemos estão sendo \\nreinventados. Aqueles que não acompanharem essa evolução natural ficarão para trás, como \\ntantas vezes vimos na história humana. Aprenda o máximo que puder, sobre diferentes temas, \\ndesde habilidades interpessoais até habilidades técnicas. O único limite sobre o que você pode \\naprender é o que você impõe a si mesmo.  \\n“Seja Bom em Aprender”. Mantenha -se em modo constante de aprendizado.  \\nEquipe DSA  \\nwww.datascienceacademy.com.br  \\n ', metadata={'source': 'arquivos/ArtigoDSA1.pdf', 'page': 2})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsa_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dsa_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo a API do LLM\n",
    "\n",
    "Crie sua API na OpenAI e coloque no arquivo .env na mesma pasta onde está este Jupyter Notebook.\n",
    "\n",
    "https://platform.openai.com/\n",
    "\n",
    "https://platform.openai.com/api-keys\n",
    "\n",
    "https://platform.openai.com/docs/quickstart?context=python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregando as variáveis de ambiente definidas no arquivo .env\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando o Gerador de Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o gerador de embeddings\n",
    "gerador_embeddings = OpenAIEmbeddings(api_key = os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O OpenAIEmbeddings é uma funcionalidade que permite obter representações vetoriais (embeddings) de texto, que são úteis para várias tarefas de processamento de linguagem natural, como comparação de semelhança de texto, agrupamento e classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x1161205d0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x11494ded0>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', openai_api_version='', openai_api_base=None, openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key='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', openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gerador_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_community.embeddings.openai.OpenAIEmbeddings"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(gerador_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando os Vetores de Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testando o gerador de embeddings\n",
    "vetores = gerador_embeddings.embed_query('Qual habilidade mais importante na era da IA?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vetores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vetores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.002467041402543643,\n",
       " 0.020015055581565046,\n",
       " -0.012389957139306136,\n",
       " -0.0015835851875652545,\n",
       " 0.02166085719248351,\n",
       " -0.020652139835772815,\n",
       " 0.0009216150625081395,\n",
       " -0.006005844181685136,\n",
       " -0.02370483459963666]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vetores[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo o Vector Store\n",
    "\n",
    "Cria sua conta gratuita no Pinecone, valide a conta, crie um índice chamado dsa-index e crie a chave da API. A chave da API deve ser colocada no arquivo .env na mesma pasta onde está este Jupyter Notebook.\n",
    "\n",
    "https://www.pinecone.io/\n",
    "\n",
    "https://app.pinecone.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciando o Pinecone\n",
    "pinecone.init(api_key = os.environ['PINECONE_API_KEY'], environment = 'gcp-starter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa linha de código acima é usada para configurar a conexão entre o seu script Python e o Pinecone, permitindo que você utilize as funcionalidades do Pinecone, como inserir, consultar e gerenciar dados de vetores em suas aplicações. Lembre-se de que o uso do Pinecone e a exposição de chaves de API em scripts ou repositórios públicos deve ser feito com cautela para evitar acessos não autorizados ou uso indevido dos seus recursos no Pinecone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o nome do índice (criado no console do Pinecone)\n",
    "index_name = 'dsa-index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando os vetores no índice\n",
    "index = Pinecone.from_documents(dsa_doc, gerador_embeddings, index_name = index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_community.vectorstores.pinecone.Pinecone"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a função de busca por similaridade\n",
    "def busca_similaridade(query, k = 2):\n",
    "    \n",
    "    # Utiliza o método 'similarity_search' do objeto 'index' para buscar os 'k' resultados \n",
    "    # mais semelhantes à 'query'\n",
    "    matching_results = index.similarity_search(query, k)\n",
    "    \n",
    "    # Retorna os resultados correspondentes da busca de similaridade\n",
    "    return matching_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando a App do Assistente Pessoal com LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria instância do LLM\n",
    "llm_dsa = OpenAI(openai_api_key = os.environ['OPENAI_API_KEY'], temperature = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/modules/chains/document/stuff\n",
    "\n",
    "https://js.langchain.com/docs/use_cases/question_answering/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria a chain para perguntas e respostas em documentos\n",
    "chain = load_qa_chain(llm_dsa, chain_type = 'stuff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a função para obter resposta\n",
    "def obter_resposta(query):\n",
    "\n",
    "    # Chama a função 'busca_similaridade' com a 'query' fornecida e armazena o resultado em 'doc_search'\n",
    "    doc_search = busca_similaridade(query)\n",
    "        \n",
    "    # Utiliza o objeto 'chain' para executar a função run e processar a 'query' e os documentos encontrados, \n",
    "    # armazenando a resposta em 'response'\n",
    "    response = chain.run(input_documents = doc_search, question = query)\n",
    "    \n",
    "    # Retorna a resposta obtida do processamento anterior\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executando o Assistente de IA e Conversando com PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pergunta para o arquivo pdf\n",
    "dsa_prompt1 = \"O que a pesquisa recente da Salesforce descobriu?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém a resposta\n",
    "resposta1 = obter_resposta(dsa_prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A pesquisa recente da Salesforce descobriu que três quartos dos trabalhadores do mundo se sentem despreparados para os empregos que podem encontrar do outro lado do marco em que o número de horas trabalhadas pelas máquinas será igual ao número de horas trabalhadas pelos humanos.\n"
     ]
    }
   ],
   "source": [
    "print(resposta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pergunta para o arquivo pdf\n",
    "dsa_prompt2 = \"Qual percentual de empregadores estão tendo problemas para preencher vagas digitais com candidatos qualificados?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém a resposta\n",
    "resposta2 = obter_resposta(dsa_prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Quase 60% dos empregadores estão tendo problemas para preencher vagas digitais com candidatos qualificados.\n"
     ]
    }
   ],
   "source": [
    "print(resposta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pergunta para o arquivo pdf\n",
    "dsa_prompt3 = \"Qual a habilidade mais importante na era da Inteligência Artificial?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém a resposta\n",
    "resposta3 = obter_resposta(dsa_prompt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A habilidade mais importante na era da Inteligência Artificial é a capacidade de aprender constantemente e se adaptar a novas tecnologias rapidamente.\n"
     ]
    }
   ],
   "source": [
    "print(resposta3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Data Science Academy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -a \"Data Science Academy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%watermark -v -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%watermark --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
